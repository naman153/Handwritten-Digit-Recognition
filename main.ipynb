{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data and preprocess it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train.shape , y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_img(i):\n",
    "    plt.imshow(x_train[i], cmap='binary')\n",
    "    plt.title(y_train[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAHV0lEQVR4nO3dP4iUdx7H8edx13/xEjd2Kqk9bGKCYQtBTQStNFdKDkQrhRgbJQQs0hwI2unaiZUkjWQLOVAUtPACYpGQxMM9WBBJEeEQlUs4DDLXpLiDne/E2fHmM7OvF9j44cn+ML7zJP4y2nY6nQbIs2zYBwAWJk4IJU4IJU4IJU4IJU4IJU4IJc4x0bbtrbZt/9227b9++zY37DOxOOIcL0c7nc4ffvu2adiHYXHECaHEOV5OtW37z7Zt/9a27c5hH4bFaf2/teOhbdvppmn+3jTN86Zp9jdNM9M0zZZOpzM/1IPRN3GOqbZtrzZN89dOp3Nu2GehP/61dnx1mqZph30I+ifOMdC27VTbtnvatl3Vtu1k27Z/bppme9M0V4d9Nvo3OewDMBDLm6b5S9M0f2ya5kXTNPebpvlTp9P5x1BPxaL4b04I5V9rIZQ4IZQ4IZQ4IVSvX631q0Xw6i14H+3NCaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaEmh30A/teLFy/K/enTp6/068/MzHTdfvnll/LZubm5cj9//ny5nzhxouv25Zdfls+uWrWq3D/77LNy//zzz8t9GLw5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZR7zgU8fPiw3J8/f17uX3/9dbnfvn276/bkyZPy2cuXL5f7ML311lvl/sknn5T77Oxs1+31118vn3377bfLfceOHeWeyJsTQokTQokTQokTQokTQokTQrWdTqfay3FUffPNN+X+wQcflPur/thWqomJiXK/ePFiua9Zs6bvr71hw4Zyf/PNN8t906ZNfX/t/4N2oe/05oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQS/Ke8/Hjx+U+PT1d7vPz84M8zkD1Onuv+8CbN2923VasWFE+u1TvfwfAPSeMEnFCKHFCKHFCKHFCKHFCKHFCqCX5W2OuW7eu3M+cOVPuV65cKfd33nmn3I8dO1bulS1btpT7jRs3yr3XZyp/+OGHrtvZs2fLZxksb04IJU4IJU4IJU4IJU4IJU4IJU4ItSQ/z7lYz549K/def1zd4cOHu24XLlwon7106VK5f/TRR+VOJJ/nhFEiTgglTgglTgglTgglTgglTgi1JD/PuVhvvPHGop5fu3Zt38/2ugfdv39/uS9b5p/Ho8LfKQglTgglTgglTgglTgglTgjlI2ND8PPPP3fd9u7dWz5769atcr969Wq57969u9wZCh8Zg1EiTgglTgglTgglTgglTgglTgjlnjPM/Px8ub/77rvlPjU1Ve7vv/9+uW/durXr9vHHH5fPtu2C13X05p4TRok4IZQ4IZQ4IZQ4IZQ4IZQ4IZR7zhEzOztb7ocOHSr3Xn98YeXUqVPlfuDAgXJfv3593197zLnnhFEiTgglTgglTgglTgglTgglTgjlnnPMfP/99+V+/Pjxcr9x40bfX/vIkSPlfvLkyXLfuHFj3197xLnnhFEiTgglTgglTgglTgglTgglTgjlnnOJefLkSblfuXKl63bw4MHy2R4/l5pdu3aV+/Xr18t9jLnnhFEiTgglTgglTgglTgglTgjlKoXfbeXKleX+66+/lvvy5cvL/dq1a123nTt3ls+OOFcpMErECaHECaHECaHECaHECaHECaEmh30ABuu7774r98uXL5f73bt3u2697jF72bx5c7lv3759UX/9cePNCaHECaHECaHECaHECaHECaHECaHcc4aZm5sr93PnzpX7V199Ve4//fTTS5/p95qcrH86rV+/vtyXLfOu+G9+NCCUOCGUOCGUOCGUOCGUOCGUOCGUe85XoNdd4hdffNF1m5mZKZ998OBBP0caiPfee6/cT548We779u0b5HHGnjcnhBInhBInhBInhBInhBInhHKVsoBHjx6V+71798r96NGj5X7//v2XPtOgTE9Pl/unn37adfvwww/LZ33ka7D8aEIocUIocUIocUIocUIocUIocUKosb3nfPz4cdft8OHD5bPffvttuc/Pz/dzpIHYtm1buR8/frzc9+zZU+6rV69+6TPxanhzQihxQihxQihxQihxQihxQihxQqjYe847d+6U++nTp8v97t27Xbcff/yxrzMNymuvvdZ1O3bsWPlsr99+cs2aNX2diTzenBBKnBBKnBBKnBBKnBBKnBBKnBAq9p5zdnZ2UftibN68udz37t1b7hMTE+V+4sSJrtvU1FT5LEuHNyeEEieEEieEEieEEieEEieEEieEajudTrWXIzAQ7ULf6c0JocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJoXr9EYAL/pZ9wKvnzQmhxAmhxAmhxAmhxAmhxAmh/gMtdTK4mBwmYAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    plot_input_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the images\n",
    "\n",
    "#normalising the image to [0,1] range\n",
    "x_train=x_train.astype(np.float32)/255\n",
    "x_test=x_test.astype(np.float32)/255\n",
    "\n",
    "x_train=np.expand_dims(x_train, -1)\n",
    "x_test=np.expand_dims(x_test, -1)\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape= (28,28,1), activation= 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Earlystopping\n",
    "es= EarlyStopping(monitor='val_acc', min_delta=0.01, patience=4, verbose=1)\n",
    "\n",
    "#Model CheckPoint\n",
    "\n",
    "mc= ModelCheckpoint(\"./bestmodel.h5\", monitor=\"val_acc\", verbose=1, save_best_only=True) \n",
    "\n",
    "cb=[es, mc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1313/1313 [==============================] - 105s 73ms/step - loss: 0.2182 - accuracy: 0.9330 - val_loss: 0.0829 - val_accuracy: 0.9741\n",
      "Epoch 2/50\n",
      "1313/1313 [==============================] - 92s 70ms/step - loss: 0.0708 - accuracy: 0.9779 - val_loss: 0.0561 - val_accuracy: 0.9824\n",
      "Epoch 3/50\n",
      "1313/1313 [==============================] - 91s 70ms/step - loss: 0.0539 - accuracy: 0.9830 - val_loss: 0.0531 - val_accuracy: 0.9846\n",
      "Epoch 4/50\n",
      "1313/1313 [==============================] - 94s 72ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 0.0473 - val_accuracy: 0.9852\n",
      "Epoch 5/50\n",
      "1313/1313 [==============================] - 94s 72ms/step - loss: 0.0377 - accuracy: 0.9882 - val_loss: 0.0429 - val_accuracy: 0.9867\n",
      "Epoch 6/50\n",
      "1313/1313 [==============================] - 93s 71ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.0432 - val_accuracy: 0.9878\n",
      "Epoch 7/50\n",
      "1313/1313 [==============================] - 94s 72ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.0410 - val_accuracy: 0.9879\n",
      "Epoch 8/50\n",
      "1313/1313 [==============================] - 86s 65ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0414 - val_accuracy: 0.9882\n",
      "Epoch 9/50\n",
      "1313/1313 [==============================] - 90s 68ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.0435 - val_accuracy: 0.9879\n",
      "Epoch 10/50\n",
      "1313/1313 [==============================] - 89s 68ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0415 - val_accuracy: 0.9888\n",
      "Epoch 11/50\n",
      "1313/1313 [==============================] - 85s 65ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0402 - val_accuracy: 0.9892\n",
      "Epoch 12/50\n",
      "1313/1313 [==============================] - 83s 63ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.0426 - val_accuracy: 0.9892\n",
      "Epoch 13/50\n",
      "1313/1313 [==============================] - 83s 63ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.0425 - val_accuracy: 0.9885\n",
      "Epoch 14/50\n",
      "1313/1313 [==============================] - 84s 64ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.0441 - val_accuracy: 0.9892\n",
      "Epoch 15/50\n",
      "1313/1313 [==============================] - 83s 63ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.0464 - val_accuracy: 0.9892\n",
      "Epoch 16/50\n",
      "1313/1313 [==============================] - 81s 62ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.0485 - val_accuracy: 0.9882\n",
      "Epoch 17/50\n",
      "1313/1313 [==============================] - 78s 60ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.0510 - val_accuracy: 0.9886\n",
      "Epoch 18/50\n",
      "1313/1313 [==============================] - 79s 60ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0471 - val_accuracy: 0.9897\n",
      "Epoch 19/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0462 - val_accuracy: 0.9894\n",
      "Epoch 20/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0486 - val_accuracy: 0.9896\n",
      "Epoch 21/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0491 - val_accuracy: 0.9897\n",
      "Epoch 22/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0500 - val_accuracy: 0.9899\n",
      "Epoch 23/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0514 - val_accuracy: 0.9896\n",
      "Epoch 24/50\n",
      "1313/1313 [==============================] - 78s 60ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0607 - val_accuracy: 0.9874\n",
      "Epoch 25/50\n",
      "1313/1313 [==============================] - 78s 60ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.0508 - val_accuracy: 0.9888\n",
      "Epoch 26/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0465 - val_accuracy: 0.9897\n",
      "Epoch 27/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0562 - val_accuracy: 0.9898\n",
      "Epoch 28/50\n",
      "1313/1313 [==============================] - 79s 60ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0520 - val_accuracy: 0.9884\n",
      "Epoch 29/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0553 - val_accuracy: 0.9889\n",
      "Epoch 30/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.0587 - val_accuracy: 0.9893\n",
      "Epoch 31/50\n",
      "1313/1313 [==============================] - 78s 60ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0494 - val_accuracy: 0.9896\n",
      "Epoch 32/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.0499 - val_accuracy: 0.9907\n",
      "Epoch 33/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0558 - val_accuracy: 0.9892\n",
      "Epoch 34/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0564 - val_accuracy: 0.9900\n",
      "Epoch 35/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0556 - val_accuracy: 0.9899\n",
      "Epoch 36/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0554 - val_accuracy: 0.9905\n",
      "Epoch 37/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0533 - val_accuracy: 0.9904\n",
      "Epoch 38/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0518 - val_accuracy: 0.9901\n",
      "Epoch 39/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0563 - val_accuracy: 0.9903\n",
      "Epoch 40/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0669 - val_accuracy: 0.9889\n",
      "Epoch 41/50\n",
      "1313/1313 [==============================] - 79s 60ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0538 - val_accuracy: 0.9905\n",
      "Epoch 42/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0540 - val_accuracy: 0.9901\n",
      "Epoch 43/50\n",
      "1313/1313 [==============================] - 77s 59ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0601 - val_accuracy: 0.9901\n",
      "Epoch 44/50\n",
      "1313/1313 [==============================] - 78s 59ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0579 - val_accuracy: 0.9902\n",
      "Epoch 45/50\n",
      "1313/1313 [==============================] - 77s 58ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0617 - val_accuracy: 0.9902\n",
      "Epoch 46/50\n",
      "1313/1313 [==============================] - 76s 58ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0592 - val_accuracy: 0.9894\n",
      "Epoch 47/50\n",
      "1313/1313 [==============================] - 80s 61ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 0.0578 - val_accuracy: 0.9904\n",
      "Epoch 48/50\n",
      "1313/1313 [==============================] - 81s 61ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0612 - val_accuracy: 0.9901\n",
      "Epoch 49/50\n",
      "1313/1313 [==============================] - 81s 62ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0649 - val_accuracy: 0.9893\n",
      "Epoch 50/50\n",
      "1313/1313 [==============================] - 81s 62ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0570 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "his = model.fit( x_train, y_train, epochs= 50, validation_split= 0.3, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S= keras.models.load_model(\"D://CODING WORLD//PROJECTS//Handwritten_Character_Recognition//best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0436 - accuracy: 0.9921\n",
      "the accuracy is0.9921000003814697\n"
     ]
    }
   ],
   "source": [
    "score= model_S.evaluate(x_test, y_test)\n",
    "print(f\"the accuracy is{score[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12088/3276094509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Ds5Rc.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m240\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "img=cv2.imread('Ds5Rc.png')\n",
    "img= cv2.resize(img(320, 240))\n",
    "img= np.reshape(img, [1,28,28,3])\n",
    "classes= model.predict(img)\n",
    "print(classes)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
